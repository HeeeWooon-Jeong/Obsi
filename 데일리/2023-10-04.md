# [추석 끝나고 복습]
# 딥러닝이 뭘까?
-> 인공 신경망을 이용해서 컴퓨터를 학습시키는 방법
인공 신경망 -> 사람의 신경세포망으 모방해서 만들었다.
모방을 하기 위해서 우리가 가진 신경세포를 구현할 필요가 있었다.
우리 몸의 신경세포는 뉴런
-> 선형회귀로 구현한다.
**y = mx + b**

---

우리 몸의 뉴런은 모든 신호를 다 전달하지는 않았다.
활성화 함수

뉴런 + 활성화 = 퍼셉트론

XOR 문제 해결 못함

![[Pasted image 20231004091913.png]]
선 하나가 퍼셉트론 여러개의 층을 가진 퍼셉트론 다층 퍼셉트론
MLP 멀티 레이어 퍼셉트론

---
## 퍼셉트론
퍼셉트론(Perceptron)은 인공 신경망의 초기 형태 중 하나로, 프랑크 로젠블라트(Frank Rosenblatt)가 1957년에 개발한 간단한 이진 분류 알고리즘입니다. 퍼셉트론은 뇌의 신경 세포인 뉴런의 작동 방식에서 영감을 받아 만들어졌으며, 입력값을 받아 각각의 입력에 가중치를 할당하고, 이 가중치들을 조합한 값이 임계치를 넘으면 활성화되는 방식으로 동작합니다.

퍼셉트론은 다음과 같은 구성 요소로 이루어져 있습니다:

1. 입력층(Input Layer): 외부에서 입력값을 받는 부분입니다. 각 입력은 가중치와 곱해져 합산됩니다.

2. 가중치(Weights): 각 입력에 대해 가중치가 할당되며, 이 가중치는 학습을 통해 조절됩니다. 가중치는 입력 데이터에 대한 중요도를 나타냅니다.

3. 합산 함수(Summing Function): 입력과 가중치의 곱을 합산하여 하나의 값으로 계산합니다.

4. 활성화 함수(Activation Function): 합산된 값이 임계치를 넘으면 퍼셉트론이 활성화되고 출력값을 생성합니다. 활성화 함수로는 보통 계단 함수(Step Function)를 사용합니다.

5. 임계치(Threshold): 임계치는 활성화 함수에서 기준이 되는 값으로, 이 값에 따라 퍼셉트론이 활성화되거나 비활성화됩니다.

퍼셉트론은 단층 퍼셉트론과 다층 퍼셉트론(다중 퍼셉트론 또는 심층 신경망)으로 나뉩니다. 단층 퍼셉트론은 선형 분리 가능한 문제만 해결할 수 있고, XOR 문제와 같은 비선형 문제를 해결할 수 없었으나, 다층 퍼셉트론은 여러 층의 퍼셉트론을 조합하여 비선형 문제도 효과적으로 해결할 수 있습니다.

퍼셉트론은 기본적인 인공 신경망의 구성 요소 중 하나이며, 현대의 딥러닝 네트워크는 훨씬 더 복잡한 구조와 다양한 활성화 함수를 사용하여 더 복잡한 문제를 다룹니다.

---






---
활성화 함수 -> 대부분 비선형의 구조를 가지고 있다.
ex) sigmoid / softmax / relu / tanh

딥러닝 회귀   /  분류 

회귀 
 - 출력층의 활성화 함수는?  : 선형함수  
 - 손실함수  :  MSE(평균 제곱 오차)
 
이진 분류
- 출력층의 활성화 함수는 ? : sigmloid(시그모이드)
- 손실함수 :  binary_crossentropy

다중 분류
- 출력층의 활성화 함수는 ?  :  softmax 함수
- 손실함수 :  categorical_crossentropy

![[Pasted image 20231004092827.png]]


---








