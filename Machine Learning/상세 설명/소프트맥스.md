
> [!NOTE] softmax
> 소프트맥스(softmax)는 다중 클래스 분류(multi-class classification) 문제에서 주로 사용되는 활성화 함수입니다. 
> 소프트맥스 함수는 입력값을 각 클래스에 대한 확률 분포로 변환하는 역할을 합니다. 
> 주로 신경망의 출력 레이어에서 사용되며, 각 클래스에 속할 확률을 정규화하고 모든 클래스의 
> 확률 합이 1이 되도록 만듭니다. 
> 이를 통해 모델은 입력 데이터를 각 클래스에 할당할 확률을 계산할 수 있습니다.

소프트맥스 함수의 수식은 다음과 같습니다. 
입력 벡터 \(z\)의 각 요소를 \(z_i\)라고 표기하고, 소프트맥스 함수의 출력 확률 벡터를 \(p\)로 나타내면:

![[Pasted image 20231004131446.png]]

여기서:
- \(p_i\)는 입력 \(z_i\)가 속할 클래스 \(i\)에 대한 확률입니다.
- \(K\)는 클래스의 총 수입니다.
- \(e\)는 자연상수(약 2.71828)를 나타냅니다.
- 분모에 있는 합계는 모든 클래스에 대한 확률을 정규화하기 위해 사용됩니다.B

주요 특징과 역할:
1. **확률 분포 생성**: 소프트맥스 함수를 사용하면 모델의 출력을 각 클래스에 대한 확률 분포로 변환합니다. 
	이를 통해 입력 데이터가 각 클래스에 속할 확률을 모델이 예측할 수 있습니다.

2. **정규화**: 소프트맥스 함수는 출력 값을 정규화하여 모든 클래스의 확률의 합이 1이 되도록 만듭니다. 
	이는 확률적 해석이 가능하도록 도와주며, 모델이 더 강력하게 일반화되도록 합니다.

3. **다중 클래스 분류**: 소프트맥스 함수는 다중 클래스 분류 문제에서 주로 사용됩니다. 
	이 문제에서 하나의 입력 데이터가 여러 개의 클래스 중 하나에 속할 확률을 예측하는 데 사용됩니다.

4. **경사 하강법과 손실 함수**: 소프트맥스 함수와 교차 엔트로피 손실(Cross-Entropy Loss)과 함께 
	사용하여 모델을 학습합니다. 
	소프트맥스 출력과 실제 클래스 레이블 간의 차이를 최소화하도록 모델을 학습합니다.

소프트맥스 함수는 다중 클래스 분류 작업에서 중요한 역할을 하며, 
신경망 및 머신 러닝에서 흔히 사용됩니다. 
이 함수는 각 클래스에 대한 확률을 계산하므로 모델의 예측을 해석하기 쉽게 만들어줍니다.

---
# 쉬운버전

소프트맥스(softmax) 함수는 주로 다중 클래스 분류 작업에서 사용되는 함수입니다. 이 함수를 간단하게 설명하면 다음과 같습니다:

상상해보세요, 여러 가지 과일 사진을 보여주고, 각각의 과일에 대한 확률을 예측하려고 할 때 어떻게 할까요? 소프트맥스 함수가 도와줍니다.

1. 먼저, 각 과일에 대한 예측값을 얻습니다. 이 값은 각 과일이 얼마나 해당 사진과 일치하는지를 나타냅니다.

2. 소프트맥스 함수는 이 예측값들을 가지고 각 과일에 속할 확률을 계산합니다. 이때, 확률은 모든 과일에 대한 예측값을 고려하여 계산됩니다.

3. 소프트맥스 함수를 통과한 결과를 보면, 각각의 과일에 대한 확률이 나옵니다. 이 확률값을 보면 어떤 과일이 사진과 더 잘 일치하는지 알 수 있습니다. 가장 높은 확률을 갖는 과일이 모델의 예측입니다.

간단히 말해, 소프트맥스 함수는 다양한 선택지 중에서 어떤 선택지가 가장 확률적으로 가능성이 높은지를 계산하는 데 사용됩니다. 
이를 통해 다중 클래스 분류 작업에서 어떤 클래스에 속할 확률을 예측할 수 있습니다.

예측값 ->  모든 데이터에 예측값 적용 -> 데이터에 예측값을 적용했을때 확률

---

