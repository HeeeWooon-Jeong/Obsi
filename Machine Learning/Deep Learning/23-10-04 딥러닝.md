
### 1. 회귀

- 손실 함수(loss) : MSE( 평균 제곱 오차 )

- 출력층의 뉴런 갯수 : 1개

- 출력층의 활성화 함수 : linear -> 기본 값

### 2. [[이진분류]]
	
- 손실함수( loss ) : binary_crossnropy

- 출력층 뉴런 갯수 : 1개

- 출력층의 활성화 함수 :  sigmoid
  

### 3. [[다중분류]]

- 손실함수( loss ) : categorical_crossntropy

- 출력층 뉴런의 갯수 :
   정답의 갯수(원-핫 인코딩 되어진 정답의 종류 만큼)

- 출력층의 활성화 함수 : softmax
   
---

[움직임으로 보는 최적화 함수 자세한 링크 모름](https://www.slideshare.net/yongho/ss-79607172)

# 옵티마이저 종류
![[Pasted image 20231004122005.png|]]

---

[딥러닝 강의 메타코드 M](https://www.youtube.com/@mcodeM/featured)



> [!NOTE] 오차역전파
> 오차 역전파(Backpropagation)는 인공 신경망에서 학습 알고리즘 중 하나로, 
> 네트워크의 가중치(weight)를 조정하기 위한 방법입니다. 
> 오차 역전파는 경사 하강법(Gradient Descent)과 함께 사용되며, 
> 신경망의 출력과 실제 값 사이의 오차를 계산하고 이 오차를 사용하여 네트워크의 
> 가중치를 업데이트합니다.

오차 역전파의 주요 단계는 다음과 같습니다:

1. **순전파 (Forward Propagation)**:
   - 입력 데이터를 모델에 주입하고, 모델은 순전파를 통해 예측을 생성합니다.
   - 각 레이어에서 활성화 함수를 사용하여 출력을 계산합니다.
   - 예측과 실제 값을 비교하여 오차를 계산합니다.

2. **오차 계산 (Error Calculation)**:
   - 실제 값과 예측 값 사이의 오차를 계산합니다.
   - 일반적으로 평균 제곱 오차(Mean Squared Error) 또는 교차 엔트로피 손실(Cross-Entropy Loss)와 같은 손실 함수를 사용합니다.

3. **오차 역전파 (Backpropagation)**:
   - 오차를 역방향으로 전파하면서 각 레이어의 가중치에 대한 그래디언트(기울기)를 계산합니다.
   - 첫 번째 레이어부터 마지막 레이어까지 역순으로 진행합니다.
   - 오차를 각 레이어의 활성화 함수와 가중치를 고려하여 계산합니다.

4. **가중치 업데이트 (Weight Update)**:
   - 계산된 그래디언트를 사용하여 가중치를 업데이트합니다.
   - 일반적으로 경사 하강법 또는 그 변형 알고리즘을 사용하여 가중치를 업데이트합니다.
   - 학습률(learning rate)과 함께 가중치를 업데이트하며, 학습률은 가중치 업데이트의 크기를 조절합니다.

5. **반복 (Iteration)**:
   - 오차 역전파와 가중치 업데이트 단계를 여러 번 반복하여 네트워크가 수렴할 때까지 학습합니다.
   - 일반적으로 모든 훈련 데이터를 한 번 사용한 것을 에포크(epoch)라고 하며, 여러 에포크를 거쳐 모델을 학습합니다.

오차 역전파를 통해 신경망은 학습 데이터를 기반으로 가중치를 조정하며, 이를 통해 입력 데이터에 대한 정확한 예측을 수행할 수 있습니다. 오차 역전파는 딥러닝에서 매우 중요한 학습 알고리즘이며, 다양한 변형과 최적화 기술이 개발되어 네트워크의 학습을 더 효율적으로 만듭니다.

---
# 언제 사용하는가

오차 역전파(Backpropagation)는 신경망(인공 신경망)을 학습시킬 때 주로 사용됩니다. 
신경망은 다양한 분야와 문제에 적용할 수 있는 강력한 모델인데, 이 모델을 학습시키기 위해 
오차 역전파가 필요합니다. 다음은 오차 역전파가 사용되는 몇 가지 상황입니다:

1. **지도 학습 문제**: 오차 역전파는 지도 학습(Supervised Learning) 문제에서 주로 사용됩니다. 
	이는 입력 데이터와 정답 레이블을 가지고 모델을 학습하는 문제 유형입니다. 
	예를 들어, 이미지 분류, 텍스트 분류, 음성 인식과 같은 문제는 지도 학습의 일부로서 오차 역전파를 사용합니다.

3. **딥러닝 및 신경망**: 오차 역전파는 딥러닝과 신경망 모델에서 가장 기본적인 학습 알고리즘 중 
	하나입니다. 
	딥러닝은 심층 신경망을 사용하는 머신 러닝의 한 분야이며, 오차 역전파를 통해 이러한 신경망을 학습시킵니다.

5. **다중 클래스 및 다중 레이어**: 오차 역전파는 다중 클래스 분류와 다중 레이어 신경망에서 특히 
	효과적입니다. 
	다중 클래스 분류 문제에서는 여러 개의 클래스 중 하나를 선택하는 작업을 수행하며, 다중 레이어 신경망은 여러 개의 은닉 레이어를 갖는 복잡한 구조를 가지고 있습니다.

7. **미분 가능한 활성화 함수 사용**: 오차 역전파는 주로 미분 가능한 활성화 함수(예: 시그모이드, ReLU, 소프트맥스)와 함께 사용됩니다. 
	이러한 활성화 함수를 사용하면 그래디언트(기울기)를 계산하기 쉽고, 가중치 업데이트를 수행할 수 있습니다.

9. **데이터 양과 복잡성**: 오차 역전파는 대규모 데이터셋 및 복잡한 모델에서 특히 효과적입니다. 
	딥러닝과 같은 신경망 모델은 대량의 데이터와 복잡한 문제를 다룰 때 높은 성능을 발휘하며, 
	오차 역전파를 사용하여 이러한 모델을 효과적으로 학습시킵니다.

오차 역전파는 다양한 분야와 문제에 사용되며, 신경망 모델을 학습시키는 데 중요한 역할을 합니다.
하지만 데이터의 특성, 모델의 구조, 문제의 복잡성 등에 따라 다른 학습 알고리즘을 사용하는 
경우도 있으므로 항상 문제에 맞는 적절한 학습 방법을 선택해야 합니다.



