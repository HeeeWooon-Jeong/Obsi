회귀(Regression) 문제를 해결하는 데 포함되는 주요 최적화 기법 중 하나입니다. 
회귀 문제는 종속 변수와 독립 변수 간의 관계를 모델링하고, 주어진 데이터에 대한 예측을 
수행하는 것을 목표로 합니다. 이 때, 경사 하강법은 회귀 모델의 파라미터(계수)를 최적화하기 
위한 방법 중 하나로 활용됩니다.

---

![](https://i.imgur.com/Vt67DhT.png)
	잔차 제곱의 합 = 선형회귀에서 쓰던 **y= mx + b**
	최소 제곱법     =  잔차제곱의 합을 최소화 하는 방법 -- 노이즈에 취약하다는 단점!

![](https://i.imgur.com/ycLbCnT.png)
이상치에 취약함  -- 최소 제곱법

---
위 문제를 해결하기 위한게 --> 경사 하강법

![](https://i.imgur.com/3WE4FwQ.png)
수렴

![](https://i.imgur.com/e6tWxsb.png)
발산

보폭이 작으면 여러번 수행해야하고
보폭이 크면 목표지점을 찾아 가기가 어렵다  

수렴 / 발산
== 학습률

![](https://i.imgur.com/Y7ulzzc.png)
일반적으로 아래의 값들을 많이 사용함

---

경사하강법에서  최적의 파라미터를 찾기 위해 훈련세트에 있는 모든데이터를 한번씩 다 사용하는것을
== Epoch에포크

경사하강법은 모든데이터를 사용하기 때문에 컴퓨터 자원을 많이 필요로 하고 
시간도 오래걸릴 수 있음

--> 이것을 보완한것이

![](https://i.imgur.com/S0NeqgT.png)

매 단계마다 딱 하나의 데이터만 지정해서 기울기를 계산하는 작업 수행
## [경사하강법을 gif 로 보기](https://alykhantejani.github.io/images/gradient_descent_line_graph.gif)

---



